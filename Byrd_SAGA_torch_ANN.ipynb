{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary modules here, for clearness\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集/模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP + MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "optConfig = {\n",
    "    'honestSize': 50,\n",
    "    'byzantineSize': 20,\n",
    "\n",
    "    'rounds': 15,\n",
    "    'displayInterval': 1000,\n",
    "\n",
    "    'weight_decay': 0.00,\n",
    "    \n",
    "    'fixSeed': False,\n",
    "    'SEED': 100,\n",
    "    \n",
    "    'batchSize': 5,\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "# 数据集属性\n",
    "dataSetConfig = {\n",
    "    'name': 'mnist',\n",
    "\n",
    "    'dataSet' : 'mnist',\n",
    "    'dataSetSize': 60000,\n",
    "    'maxFeature': 784,\n",
    "\n",
    "    'honestNodeSize': 50,\n",
    "    'byzantineNodeSize': 20,\n",
    "\n",
    "    'rounds': 15,\n",
    "    'displayInterval': 1000,\n",
    "}\n",
    "\n",
    "SGDConfig = optConfig.copy()\n",
    "SGDConfig['gamma'] = 1e-1\n",
    "\n",
    "batchConfig = optConfig.copy()\n",
    "batchConfig['batchSize'] = 50\n",
    "batchConfig['gamma'] = 5e-1\n",
    "\n",
    "SVRGConfig = optConfig.copy()\n",
    "SVRGConfig['snapshotInterval'] = dataSetConfig['dataSetSize']\n",
    "SVRGConfig['gamma'] = 1e-1\n",
    "\n",
    "SAGAConfig = optConfig.copy()\n",
    "SAGAConfig['gamma'] = 1e-1\n",
    "\n",
    "SARAHConfig = optConfig.copy()\n",
    "SARAHConfig['gamma'] = 1e-1\n",
    "\n",
    "# 加载数据集\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert a PIL Image or numpy.ndarray to tensor.\n",
    "    # Normalize a tensor image with mean 0.1307 and standard deviation 0.3081\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./dataset/', \n",
    "                            train=True, \n",
    "                            transform=train_transform,\n",
    "                            download=False)\n",
    "validate_dataset = torchvision.datasets.MNIST(root='./dataset/', \n",
    "                           train=False, \n",
    "                           transform=test_transform,\n",
    "                           download=False)\n",
    "\n",
    "# 模型\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Inputs                Linear/Function        Output\n",
    "    [128, 1, 28, 28]   -> Linear(28*28, 100) -> [128, 100]  # first hidden layer\n",
    "                       -> ReLU               -> [128, 100]  # relu activation function, may sigmoid\n",
    "                       -> Linear(100, 100)   -> [128, 100]  # third hidden layer\n",
    "                       -> ReLU               -> [128, 100]  # relu activation function, may sigmoid\n",
    "                       -> Linear(100, 10)    -> [128, 10]   # Classification Layer                                                          \n",
    "   \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, SEED=100):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.classification_layer = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.relu1 = nn.Tanh()\n",
    "        self.relu2 = nn.Tanh()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.relu2 = nn.ReLU()\n",
    "        \n",
    "#         torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "#         model = local_models[0]\n",
    "#         for p in model.parameters():\n",
    "#             torch.nn.init.normal_(p, mean=0, std=2/p.numel())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\n",
    "           Should be overridden by all subclasses.\n",
    "        Args:\n",
    "            x: [batch_size, channel, height, width], input for network\n",
    "        Returns:\n",
    "            out: [batch_size, n_classes], output from network\n",
    "        \"\"\"\n",
    "        \n",
    "        out = x.view(x.size(0), -1) # flatten x in [128, 784]\n",
    "        out = self.relu1(out)\n",
    "        out = self.hidden(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.classification_layer(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "# 模型工厂\n",
    "def modelFactory(SEED=100):\n",
    "    return MLP(784, 50, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet + CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ResNet50 + CIFAR10\n",
    "# optConfig = {\n",
    "#     'honestSize': 10,\n",
    "#     'byzantineSize': 4,\n",
    "\n",
    "#     'rounds': 15,\n",
    "#     'displayInterval': 6000,\n",
    "    \n",
    "#     'weight_decay': 0.0001,\n",
    "    \n",
    "#     'fixSeed': False,\n",
    "#     'SEED': 100,\n",
    "    \n",
    "#     'batchSize': 5,\n",
    "#     'shuffle': True,\n",
    "# }\n",
    "\n",
    "# SGDConfig = optConfig.copy()\n",
    "# SGDConfig['gamma'] = 1e-1\n",
    "\n",
    "# batchConfig = optConfig.copy()\n",
    "# batchConfig['batchSize'] = 50\n",
    "# batchConfig['gamma'] = 5e-1\n",
    "\n",
    "# SVRGConfig = optConfig.copy()\n",
    "# SVRGConfig['snapshotInterval'] = dataSetConfig['dataSetSize']\n",
    "# SVRGConfig['gamma'] = 1e-1\n",
    "\n",
    "# SAGAConfig = optConfig.copy()\n",
    "# SAGAConfig['gamma'] = 1e-1\n",
    "\n",
    "# SARAHConfig = optConfig.copy()\n",
    "# SARAHConfig['gamma'] = 1e-1\n",
    "\n",
    "# # 数据集属性\n",
    "# dataSetConfig = {\n",
    "#     'name': 'CIFAR-10',\n",
    "\n",
    "#     'dataSet' : 'CIFAR-10',\n",
    "#     'dataSetSize': 60000,\n",
    "#     'maxFeature': 32*32*3,\n",
    "# }\n",
    "\n",
    "# # 加载数据集\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./dataset/',\n",
    "#                                              train=True, \n",
    "#                                              transform=preprocess,\n",
    "#                                              download=False)\n",
    "# validate_dataset = torchvision.datasets.CIFAR10(root='./dataset/',\n",
    "#                                             train=False, \n",
    "#                                             transform=preprocess)\n",
    "\n",
    "# 模型工厂\n",
    "# def modelFactory(SEED=100):\n",
    "#     return torchvision.models.resnet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = './cache/' + dataSetConfig['name'] + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 报告函数\n",
    "def log(*k, **kw):\n",
    "    timeStamp = time.strftime('[%m-%d %H:%M:%S] ', time.localtime())\n",
    "    print(timeStamp, end='')\n",
    "    print(*k, **kw)\n",
    "def debug(*k, **kw):\n",
    "    timeStamp = time.strftime('[%m-%d %H:%M:%S] (debug)', time.localtime())\n",
    "    print(timeStamp, end='')\n",
    "    print(*k, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVarience(w_local, honestSize):\n",
    "    avg = w_local[:honestSize].mean(dim=0)\n",
    "    s = 0\n",
    "    for w in w_local[:honestSize]:\n",
    "        s += (w - avg).norm()**2\n",
    "    s /= honestSize\n",
    "    return s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(model, loader, device):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    \n",
    "    for material, targets in loader:\n",
    "        material, targets = material.to(device), targets.to(device)\n",
    "        outputs = model(material)\n",
    "        \n",
    "        l = loss_func(outputs, targets)\n",
    "\n",
    "        loss += l.item() * len(targets)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        accuracy += (predicted == targets).sum().item()\n",
    "        total += len(targets)\n",
    "    \n",
    "    loss /= total\n",
    "    accuracy /= total\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚合函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(wList):\n",
    "    return torch.mean(wList, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gm(wList):\n",
    "    max_iter = 80\n",
    "    tol = 1e-5\n",
    "    guess = torch.mean(wList, dim=0)\n",
    "    for _ in range(max_iter):\n",
    "        dist_li = torch.norm(wList-guess, dim=1)\n",
    "        for i in range(len(dist_li)):\n",
    "            if dist_li[i] == 0:\n",
    "                dist_li[i] = 1\n",
    "        temp1 = torch.sum(torch.stack([w/d for w, d in zip(wList, dist_li)]), dim=0)\n",
    "        temp2 = torch.sum(1/dist_li)\n",
    "        guess_next = temp1 / temp2\n",
    "        guess_movement = torch.norm(guess - guess_next)\n",
    "        guess = guess_next\n",
    "        if guess_movement <= tol:\n",
    "            break\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Krum_(nodeSize, byzantineSize):\n",
    "    honestSize = nodeSize - byzantineSize\n",
    "    dist = torch.zeros(nodeSize, nodeSize, dtype=torch.float32)\n",
    "    def Krum(wList):\n",
    "        for i in range(nodeSize):\n",
    "            for j in range(i, nodeSize):\n",
    "                distance = wList[i].data - wList[j].data\n",
    "                distance = (distance*distance).sum()\n",
    "                dist[i][j] = distance.data\n",
    "                dist[j][i] = distance.data\n",
    "        k = nodeSize - byzantineSize - 2 + 1 # 算上自己和自己的0.00\n",
    "        topv, _ = dist.topk(k=k, dim=1)\n",
    "        sumdist = -topv.sum(dim=1)\n",
    "        resindex = sumdist.topk(1)[1].squeeze()\n",
    "        return wList[resindex]\n",
    "    return Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(wList):\n",
    "    return wList.median(dim=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(message, byzantineSize):\n",
    "    wList = [torch.cat([p.flatten() for p in parameters]) for parameters in message]\n",
    "    wList.extend([torch.zeros_like(wList[0]) for _ in range(byzantineSize)])\n",
    "    wList = torch.stack(wList)\n",
    "    return wList\n",
    "def unflatten_vector(vector, model):\n",
    "    paraGroup = []\n",
    "    cum = 0\n",
    "    for p in model.parameters():\n",
    "        newP = vector[cum:cum+p.numel()]\n",
    "        paraGroup.append(newP.view_as(p))\n",
    "        cum += p.numel()\n",
    "    return paraGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSample(dataset, batchSize):\n",
    "    m, t = zip(*random.sample(dataset, batchSize))\n",
    "    material, targets = torch.cat(m), torch.tensor(t)\n",
    "    return material, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPara(module, useString=True):\n",
    "    para = sum([x.nelement() for x in module.parameters()])\n",
    "    if not useString:\n",
    "        return para\n",
    "    elif para >= 2**20:\n",
    "        return '{:.2f}M'.format(para / 2**20)\n",
    "    elif para >= 2**10:\n",
    "        return '{:.2f}K'.format(para / 2**10)\n",
    "    else:\n",
    "        return str(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "报告函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(r, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy, var=None):\n",
    "    varStr = '' if (var == None) else ' var={:.2e}'.format(var)\n",
    "    log('[{}/{}](interval: {:.0f}) train: loss={:.4f} acc={:.2f} val: loss={:.4f} acc={:.2f}{}'\n",
    "        .format(r, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy, varStr)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CentralSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def CentralSGD(model, gamma, aggregate, weight_decay, attack=None, \n",
    "          rounds=10, displayInterval=1000, \n",
    "          device='cpu', SEED=100, fixSeed=False, \n",
    "          batchSize=1,\n",
    "          **kw):\n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "\n",
    "    # 顺序遍历loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=False)\n",
    "    validate_loader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "    # 随机取样器\n",
    "    randomSampler = torch.utils.data.sampler.RandomSampler(\n",
    "        train_dataset, \n",
    "        num_samples=rounds*displayInterval*batchSize, \n",
    "        replacement=True\n",
    "    )\n",
    "    train_random_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batchSize, \n",
    "        sampler=randomSampler,\n",
    "    )\n",
    "    randomIter = iter(train_random_loader)\n",
    "    \n",
    "    # 求初始误差\n",
    "    trainLoss, trainAccuracy = calculateAccuracy(model, train_loader, device)\n",
    "    valLoss, valAccuracy = calculateAccuracy(model, validate_loader, device)\n",
    "\n",
    "    trainLossPath = [trainLoss]\n",
    "    trainAccPath = [trainAccuracy]\n",
    "    valLossPath = [valLoss]\n",
    "    valAccPath = [valAccuracy]\n",
    "    \n",
    "    report(0, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "\n",
    "    for r in range(rounds):\n",
    "        model.train()\n",
    "        for k in range(displayInterval):\n",
    "            # 读取数据\n",
    "            material, targets = next(randomIter)\n",
    "            material, targets = material.to(device), targets.to(device)\n",
    "\n",
    "            # 随机梯度\n",
    "            # --------------------\n",
    "            # 预测\n",
    "            outputs = model(material)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            # 反向传播\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # 更新\n",
    "            for para in model.parameters():\n",
    "                para.data.add_(-gamma, para.grad)\n",
    "                para.data.add_(-weight_decay, para)\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        trainLoss, trainAccuracy = calculateAccuracy(model, train_loader, device)\n",
    "        valLoss, valAccuracy = calculateAccuracy(model, validate_loader, device)\n",
    "\n",
    "        trainLossPath.append(trainLoss)\n",
    "        trainAccPath.append(trainAccuracy)\n",
    "        valLossPath.append(valLoss)\n",
    "        valAccPath.append(valAccuracy)\n",
    "\n",
    "        report(r+1, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "    return model, trainLossPath, trainAccPath, valLossPath, valAccPath, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central SARAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def CentralSARAH(model, gamma, aggregate, weight_decay, \n",
    "          snapshotInterval=len(train_dataset),\n",
    "          rounds=10, displayInterval=1000, \n",
    "          device='cpu', SEED=100, fixSeed=False, \n",
    "          batchSize=5,\n",
    "          **kw):\n",
    "    \n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "    \n",
    "    # 初始化模型\n",
    "    lastModel = modelFactory(SEED=SEED)\n",
    "    lastModel = lastModel.to(device)\n",
    "\n",
    "    # 随机的停止期限\n",
    "    randomStop = 1\n",
    "    \n",
    "    # 顺序遍历loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=False)\n",
    "    validate_loader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=batchSize, shuffle=False)\n",
    "    \n",
    "    # 随机取样器\n",
    "    randomSampler = torch.utils.data.sampler.RandomSampler(\n",
    "        train_dataset, \n",
    "        num_samples=rounds*displayInterval*batchSize, \n",
    "        replacement=True\n",
    "    )\n",
    "    randomLoader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batchSize, \n",
    "        sampler=randomSampler,\n",
    "    )\n",
    "    randomIter = iter(randomLoader)\n",
    "    \n",
    "    # 求初始误差\n",
    "    trainLoss, trainAccuracy = calculateAccuracy(model, train_loader, device)\n",
    "    valLoss, valAccuracy = calculateAccuracy(model, validate_loader, device)\n",
    "    \n",
    "    trainLossPath = [trainLoss]\n",
    "    trainAccPath = [trainAccuracy]\n",
    "    valLossPath = [valLoss]\n",
    "    valAccPath = [valAccuracy]\n",
    "    \n",
    "    log('[SARAH]初始 train: loss={:.6f} accuracy={:.2f} validation: loss={:.6f} accuracy={:.2f}'\n",
    "        .format(trainLossPath[0], trainAccPath[0], valLossPath[0], valAccPath[0])\n",
    "    )\n",
    "\n",
    "    gradients = [torch.zeros_like(para, requires_grad=False) for para in model.parameters()]\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        for k in range(displayInterval):\n",
    "            # snapshot\n",
    "            if (r*displayInterval + k) % randomStop == 0:\n",
    "                # 清空旧梯度\n",
    "                for grad in gradients:\n",
    "                    grad.zero_()\n",
    "                for material, targets in train_loader:\n",
    "                    material, targets = material.to(device), targets.to(device)\n",
    "                    # 预测\n",
    "                    outputs = model(material)\n",
    "                    loss = loss_func(outputs, targets)\n",
    "                    # 反向传播\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "\n",
    "                    for grad, para in zip(gradients, model.parameters()):\n",
    "                        grad.data.add_(1/len(train_loader), para.grad.data)\n",
    "                for grad, para in zip(gradients, model.parameters()):\n",
    "                    grad.data.add_(weight_decay, para.data)\n",
    "                \n",
    "                # 保存旧结果\n",
    "                for oldPara, newPara in zip(lastModel.parameters(), model.parameters()):\n",
    "                    oldPara.data.copy_(newPara)\n",
    "                # 更新\n",
    "                for para, grad in zip(model.parameters(), gradients):\n",
    "                    para.data.add_(-gamma, grad)\n",
    "                # 指定下一次停止时间\n",
    "                randomStop = random.randint(1, snapshotInterval-1)\n",
    "                \n",
    "            # 更新\n",
    "            # 读取数据\n",
    "            material, targets = next(randomIter)\n",
    "            material, targets = material.to(device), targets.to(device)\n",
    "\n",
    "            # 随机梯度\n",
    "            # --------------------\n",
    "            # 预测\n",
    "            outputs = model(material)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            # 反向传播\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # 修正梯度\n",
    "            # --------------------\n",
    "            # 预测\n",
    "            outputs = lastModel(material)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            # 反向传播\n",
    "            lastModel.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # 更新梯度表\n",
    "            for pi, para in enumerate(model.parameters()):\n",
    "                gradients[pi].data.add_(1, para.grad.data)\n",
    "                gradients[pi].data.add_(weight_decay, para)\n",
    "            for pi, para in enumerate(lastModel.parameters()):\n",
    "                gradients[pi].data.sub_(1, para.grad.data)\n",
    "                gradients[pi].data.sub_(weight_decay, para)\n",
    "\n",
    "            # 保存旧结果\n",
    "            for oldPara, newPara in zip(lastModel.parameters(), model.parameters()):\n",
    "                oldPara.data.copy_(newPara)\n",
    "            # 更新\n",
    "            for para, grad in zip(model.parameters(), gradients):\n",
    "                para.data.add_(-gamma, grad)\n",
    "  \n",
    "        trainLoss, trainAccuracy = calculateAccuracy(model, train_loader, device)\n",
    "        valLoss, valAccuracy = calculateAccuracy(model, validate_loader, device)\n",
    "\n",
    "        trainLossPath.append(trainLoss)\n",
    "        trainAccPath.append(trainAccuracy)\n",
    "        valLossPath.append(valLoss)\n",
    "        valAccPath.append(valAccuracy)\n",
    "        \n",
    "        report(r+1, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "    return model, trainLossPath, trainAccPath, valLossPath, valAccPath, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def SGD(model, gamma, aggregate, weight_decay, \n",
    "          honestSize=0, byzantineSize=0, attack=None, \n",
    "          rounds=10, displayInterval=1000, \n",
    "          device='cpu', SEED=100, fixSeed=False, \n",
    "          batchSize=5,\n",
    "          **kw):\n",
    "    assert byzantineSize == 0 or attack != None\n",
    "    assert honestSize != 0\n",
    "    \n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "\n",
    "    nodeSize = honestSize + byzantineSize\n",
    "\n",
    "    # 数据分片\n",
    "    pieces = [(i*len(train_dataset)) // honestSize for i in range(honestSize+1)]\n",
    "    dataPerNode = [pieces[i+1] - pieces[i] for i in range(honestSize)]\n",
    "\n",
    "    # 回复的消息\n",
    "    message = [\n",
    "        [torch.zeros_like(para, requires_grad=False) for para in model.parameters()]\n",
    "        for _ in range(nodeSize)\n",
    "    ]\n",
    "    \n",
    "    # 顺序遍历loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=False)\n",
    "    validate_loader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=batchSize, shuffle=False)\n",
    "    \n",
    "    train_dataset_subset = [torch.utils.data.Subset(train_dataset, range(pieces[i], pieces[i+1])) for i in range(honestSize)]\n",
    "    train_loaders_splited = [\n",
    "        torch.utils.data.DataLoader(dataset=subset, batch_size=batchSize, shuffle=False)\n",
    "        for subset in train_dataset_subset\n",
    "    ]\n",
    "    \n",
    "    # 随机取样器\n",
    "    randomSampler = torch.utils.data.sampler.RandomSampler(\n",
    "        train_dataset, \n",
    "        num_samples=rounds*displayInterval*batchSize, \n",
    "        replacement=True\n",
    "    )\n",
    "    train_random_loaders_splited = [torch.utils.data.DataLoader(\n",
    "            dataset=subset,\n",
    "            batch_size=batchSize, \n",
    "            sampler=randomSampler,\n",
    "    ) for subset in train_dataset_subset]\n",
    "    randomIters = [iter(loader) for loader in train_random_loaders_splited]\n",
    "    \n",
    "    # 求初始误差\n",
    "    trainLoss, trainAccuracy = calculateAccuracy(model, train_loader)\n",
    "    valLoss, valAccuracy = calculateAccuracy(model, validate_loader)\n",
    "    \n",
    "    trainLossPath = [trainLoss]\n",
    "    trainAccPath = [trainAccuracy]\n",
    "    valLossPath = [valLoss]\n",
    "    valAccPath = [valAccuracy]\n",
    "    variencePath = []\n",
    "    \n",
    "    report(0, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "\n",
    "    for r in range(rounds):\n",
    "        for k in range(displayInterval):\n",
    "            # 诚实节点更新\n",
    "            for node in range(honestSize):\n",
    "                # 读取数据\n",
    "                material, targets = next(randomIters[node])\n",
    "                \n",
    "                # 随机梯度\n",
    "                # --------------------\n",
    "                # 预测\n",
    "                outputs = model(material)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                # 反向传播\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # 更新梯度表\n",
    "                for pi, para in enumerate(model.parameters()):\n",
    "                    message[node][pi].data.zero_()\n",
    "                    message[node][pi].data.add_(1, para.grad.data)\n",
    "                    message[node][pi].data.add_(weight_decay, para)\n",
    "\n",
    "            # 同步, Byzantine攻击\n",
    "            message_f = flatten_list(message, byzantineSize)\n",
    "            if attack != None:\n",
    "                attack(message_f, byzantineSize)\n",
    "            # 聚合\n",
    "            g_vector = aggregate(message_f)\n",
    "            # 展开\n",
    "            g = unflatten_vector(g_vector, model)\n",
    "            # 更新\n",
    "            for para, grad in zip(model.parameters(), g):\n",
    "                para.data.add_(-gamma, grad)\n",
    "  \n",
    "        var = getVarience(message_f, honestSize)\n",
    "        variencePath.append(var)\n",
    "        \n",
    "        trainLoss, trainAccuracy = calculateAccuracy(model, train_loader)\n",
    "        valLoss, valAccuracy = calculateAccuracy(model, validate_loader)\n",
    "\n",
    "        trainLossPath.append(trainLoss)\n",
    "        trainAccPath.append(trainAccuracy)\n",
    "        valLossPath.append(valLoss)\n",
    "        valAccPath.append(valAccuracy)\n",
    "        \n",
    "        report(r+1, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "    return model, trainLossPath, trainAccPath, valLossPath, valAccPath, variencePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化本地模型\n",
    "def initModel(local_models, honestSize):\n",
    "    stateDict = local_models[0].state_dict()\n",
    "    for model in local_models[1:honestSize]:\n",
    "        model.load_state_dict(stateDict)\n",
    "\n",
    "# 广播\n",
    "def broadcastPara(newPara, local_models):\n",
    "    cum = 0\n",
    "    for p in local_models[0].parameters():\n",
    "        newP = newPara[cum:cum+p.numel()]\n",
    "        p.data.copy_(newP.view_as(p))\n",
    "        cum += p.numel()\n",
    "    stateDict = local_models[0].state_dict()\n",
    "    for model in local_models[1:]:\n",
    "        model.load_state_dict(stateDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     37
    ]
   },
   "outputs": [],
   "source": [
    "def SAGA(w0, gamma, aggregate, weight_decay, honestSize=0, byzantineSize=0, attack=None, \n",
    "            rounds=10, displayInterval=1000, SEED=100, fixSeed=False, **kw):\n",
    "    assert byzantineSize == 0 or attack != None\n",
    "    assert honestSize != 0\n",
    "    \n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "\n",
    "    nodeSize = honestSize + byzantineSize\n",
    "    \n",
    "    log('开始迭代，gamma={}'.format(gamma))\n",
    "    \n",
    "    # 初始化\n",
    "    store = []\n",
    "\n",
    "    # 中间变量分配空间\n",
    "    local_models = [modelFactory(SEED=SEED) for _ in range(honestSize+byzantineSize)]\n",
    "    # 同步初始化参数\n",
    "    initModel(local_models, honestSize=honestSize)\n",
    "\n",
    "    torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "    # torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "    # torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "    \n",
    "    trainLoss = 0\n",
    "    trainAccuracy = 0\n",
    "    total = 0\n",
    "    ANY_MODEL_IS_OK = 0\n",
    "    for index, (material, targets) in enumerate(dataset):\n",
    "        outputs = local_models[ANY_MODEL_IS_OK](material)\n",
    "\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "        trainLoss += loss.item() * len(targets)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        trainAccuracy += (predicted == targets).sum().item()\n",
    "        total += len(targets)\n",
    "\n",
    "        local_models[0].zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        store.append([p.grad.clone().detach()+weight_decay*p.data for p in local_models[0].parameters()])\n",
    "\n",
    "    # 数据分片\n",
    "    pieces = [(i*len(dataset)) // honestSize for i in range(honestSize+1)]\n",
    "    dataPerNode = [pieces[i+1] - pieces[i] for i in range(honestSize)]\n",
    "\n",
    "    # G_avg每一行是单个节点上存储的均值\n",
    "    G_avg = []\n",
    "    for i in range(honestSize):\n",
    "        # storeInThisNode：该节点上梯度缓存的集合\n",
    "        storeInThisNode = store[pieces[i]: pieces[i+1]]\n",
    "        # para每一个元素是在对应节点上的一组参数\n",
    "        (*paras,) = zip(*storeInThisNode)\n",
    "        # 对所有单一节点上所有数据求平均\n",
    "        G_avg.append([sum(para)/(pieces[i+1]-pieces[i]) for para in paras])\n",
    "\n",
    "    # dataset按批划分，每批求出来的Loss已经求平均，只需要在批间求平均即可\n",
    "    trainLoss /= total\n",
    "    trainAccuracy /= total\n",
    "    lossPath = [trainLoss]\n",
    "    accPath = [trainAccuracy]\n",
    "    log('[SAGA]初始 loss={:.6f}, accuracy={:.2f}'.format(lossPath[0], accPath[0]))\n",
    "\n",
    "    for r in range(rounds):\n",
    "        trainLoss = 0\n",
    "        trainAccuracy = 0\n",
    "        total = 0\n",
    "\n",
    "        for k in range(displayInterval):\n",
    "            # 诚实节点更新\n",
    "            for node in range(honestSize):\n",
    "                model = local_models[node]\n",
    "                # 读取数据\n",
    "                index = random.randint(pieces[node], pieces[node+1]-1)\n",
    "                # 预测\n",
    "                material, targets = dataset[index]\n",
    "                outputs = model(material)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                # 统计准确率\n",
    "                trainLoss += loss.item() * len(targets)\n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                trainAccuracy += (predicted == targets).sum().item()\n",
    "                total += len(targets)\n",
    "                # 反向传播\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # 更新梯度表\n",
    "                for pi, para in enumerate(model.parameters()):\n",
    "                    old_G = store[index][pi]\n",
    "                    new_G = para.grad.data.clone()\n",
    "                    new_G.add_(weight_decay, para.data)\n",
    "\n",
    "                    gradient = new_G.data - old_G.data + G_avg[node][pi].data\n",
    "\n",
    "                    G_avg[node][pi].add_(1 / dataPerNode[node],\n",
    "                                     new_G.data - old_G.data)\n",
    "                    store[index][pi] = new_G.data\n",
    "\n",
    "                    para.data.add_(-gamma, gradient.data)\n",
    "\n",
    "            # Byzantine攻击\n",
    "            if attack != None:\n",
    "                attack(local_models, byzantineSize)\n",
    "            # 聚合\n",
    "            aggregatedPara = aggregate(local_models)\n",
    "\n",
    "            # 广播\n",
    "            broadcastPara(newPara=aggregatedPara, local_models=local_models)\n",
    "\n",
    "        trainLoss /= total\n",
    "        trainAccuracy /= total\n",
    "        lossPath.append(trainLoss)\n",
    "        accPath.append(trainAccuracy)\n",
    "        log('[SAGA]已迭代 {}/{} rounds (interval: {:.0f}), loss={:.9f}, accuracy={:.2f}'.format(\n",
    "            r+1, rounds, displayInterval, trainLoss, trainAccuracy\n",
    "        ))\n",
    "    return local_models[0], lossPath, accPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     37
    ]
   },
   "outputs": [],
   "source": [
    "def SVRG(w0, gamma, aggregate, weight_decay, honestSize=0, byzantineSize=0, attack=None, \n",
    "            snapshotInterval=6000, rounds=10, displayInterval=1000, SEED=100, fixSeed=False, **kw):\n",
    "    assert byzantineSize == 0 or attack != None\n",
    "    assert honestSize != 0\n",
    "    \n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "\n",
    "    nodeSize = honestSize + byzantineSize\n",
    "    \n",
    "    # 初始化\n",
    "    w = w0.clone().detach()\n",
    "\n",
    "    # 数据分片\n",
    "    pieces = [(i*len(dataset)) // honestSize for i in range(honestSize+1)]\n",
    "    dataPerNode = [pieces[i+1] - pieces[i] for i in range(honestSize)]\n",
    "\n",
    "    snapshot_g = torch.zeros(honestSize, len(w0), dtype=torch.float64)\n",
    "    snapshot_w = torch.zeros(len(w0), dtype=torch.float64)\n",
    "\n",
    "    path = [F(w, dataset, weight_decay)]\n",
    "    variencePath = []\n",
    "    log('[SVRG]初始 loss={:.6f}, accuracy={:.2f} gamma={:}'.format(path[0], accuracy(w, dataset), gamma))\n",
    "    \n",
    "    # 中间变量分配空间\n",
    "    message = torch.zeros(nodeSize, len(w0), dtype=torch.float64)\n",
    "\n",
    "    log('开始迭代')\n",
    "    for r in range(rounds):\n",
    "        for k in range(displayInterval):\n",
    "            # snapshot\n",
    "            if (r*displayInterval + k) % snapshotInterval == 0:\n",
    "                snapshot_g.zero_()\n",
    "                for node in range(honestSize):\n",
    "                    for index in range(pieces[node], pieces[node+1]):\n",
    "                        x, y = dataset[index]\n",
    "                        # 更新梯度表\n",
    "                        predict = LogisticRegression(w, x)\n",
    "\n",
    "                        err = (predict-y).data\n",
    "                        snapshot_g[node][:-1].add_(1/dataPerNode[node], err*x)\n",
    "                        snapshot_g[node][-1].add_(1/dataPerNode[node], err)\n",
    "                    snapshot_g[node].add_(weight_decay, w)\n",
    "                snapshot_w.copy_(w)\n",
    "            \n",
    "            # 诚实节点更新\n",
    "            message.zero_()\n",
    "            for node in range(honestSize):\n",
    "                index = random.randint(pieces[node], pieces[node+1]-1)\n",
    "\n",
    "                x, y = dataset[index]\n",
    "                # 随机梯度\n",
    "                predict = LogisticRegression(w, x)\n",
    "                err = (predict-y).data\n",
    "                message[node][:-1].add_(err, x)\n",
    "                message[node][-1].add_(err, 1)\n",
    "                message[node].add_(weight_decay, w)\n",
    "                \n",
    "                # 修正梯度\n",
    "                predict = LogisticRegression(snapshot_w, x)\n",
    "                err = (predict-y).data\n",
    "                message[node][:-1].add_(-err, x)\n",
    "                message[node][-1].add_(-err, 1)\n",
    "                message[node].add_(-weight_decay, snapshot_w)\n",
    "                \n",
    "                message[node].add_(1, snapshot_g[node])\n",
    "                \n",
    "            # 同步\n",
    "            # Byzantine攻击\n",
    "            if attack != None:\n",
    "                attack(message, byzantineSize)\n",
    "            g = aggregate(message)\n",
    "            w.add_(-gamma, g)\n",
    "            \n",
    "        loss = F(w, dataset, weight_decay)\n",
    "        acc = accuracy(w, dataset)\n",
    "        path.append(loss)\n",
    "        var = getVarience(message, honestSize)\n",
    "        variencePath.append(var)\n",
    "        log('[SVRG]已迭代 {}/{} rounds (interval: {:.0f}), loss={:.9f}, accuracy={:.2f}, var={:.9f}'.format(\n",
    "            r+1, rounds, displayInterval, loss, acc, var\n",
    "        ))\n",
    "    return w, path, variencePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def SARAH(model, gamma, aggregate, weight_decay, \n",
    "          snapshotInterval=len(train_dataset),\n",
    "          honestSize=0, byzantineSize=0, attack=None, \n",
    "          rounds=10, displayInterval=1000, \n",
    "          device='cpu', SEED=100, fixSeed=False, \n",
    "          batchSize=5,\n",
    "          **kw):\n",
    "    assert byzantineSize == 0 or attack != None\n",
    "    assert honestSize != 0\n",
    "    \n",
    "    if fixSeed:\n",
    "        random.seed(SEED)\n",
    "\n",
    "    nodeSize = honestSize + byzantineSize\n",
    "    \n",
    "    # 初始化模型\n",
    "    lastModel = modelFactory(SEED=SEED)\n",
    "\n",
    "    if device == 'cpu':\n",
    "        torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "    else:\n",
    "        torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "    \n",
    "    # 数据分片\n",
    "    pieces = [(i*len(train_dataset)) // honestSize for i in range(honestSize+1)]\n",
    "    dataPerNode = [pieces[i+1] - pieces[i] for i in range(honestSize)]\n",
    "\n",
    "    # 随机的停止期限\n",
    "    randomStop = 1\n",
    "    # 回复的消息\n",
    "    message = [\n",
    "        [torch.zeros_like(para, requires_grad=False) for para in model.parameters()]\n",
    "        for _ in range(nodeSize)\n",
    "    ]\n",
    "    \n",
    "    # 顺序遍历loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=False)\n",
    "    validate_loader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=batchSize, shuffle=False)\n",
    "    \n",
    "    train_dataset_subset = [torch.utils.data.Subset(train_dataset, range(pieces[i], pieces[i+1])) for i in range(honestSize)]\n",
    "    train_loaders_splited = [\n",
    "        torch.utils.data.DataLoader(dataset=subset, batch_size=batchSize, shuffle=False)\n",
    "        for subset in train_dataset_subset\n",
    "    ]\n",
    "    \n",
    "    # 随机取样器\n",
    "    randomSampler = torch.utils.data.sampler.RandomSampler(\n",
    "        train_dataset, \n",
    "        num_samples=rounds*displayInterval*batchSize, \n",
    "        replacement=True\n",
    "    )\n",
    "    train_random_loaders_splited = [torch.utils.data.DataLoader(\n",
    "            dataset=subset,\n",
    "            batch_size=batchSize, \n",
    "            sampler=randomSampler,\n",
    "    ) for subset in train_dataset_subset]\n",
    "    randomIters = [iter(loader) for loader in train_random_loaders_splited]\n",
    "    \n",
    "    # 求初始误差\n",
    "    trainLoss, trainAccuracy = calculateAccuracy(model, train_loader)\n",
    "    valLoss, valAccuracy = calculateAccuracy(model, validate_loader)\n",
    "    \n",
    "    trainLossPath = [trainLoss]\n",
    "    trainAccPath = [trainAccuracy]\n",
    "    valLossPath = [valLoss]\n",
    "    valAccPath = [valAccuracy]\n",
    "    variencePath = []\n",
    "    \n",
    "    log('[SARAH]初始 train: loss={:.6f} accuracy={:.2f} validation: loss={:.6f} accuracy={:.2f}'\n",
    "        .format(trainLossPath[0], trainAccPath[0], valLossPath[0], valAccPath[0])\n",
    "    )\n",
    "\n",
    "    for r in range(rounds):\n",
    "        for k in range(displayInterval):\n",
    "            # snapshot\n",
    "            if (r*displayInterval + k) % randomStop == 0:\n",
    "                for node in range(honestSize):\n",
    "                    # 清空旧梯度\n",
    "                    for grad in message[node]:\n",
    "                        grad.zero_()\n",
    "                    loader = train_loaders_splited[node]\n",
    "                    for material, targets in loader:\n",
    "                        # 预测\n",
    "                        outputs = model(material)\n",
    "                        loss = loss_func(outputs, targets)\n",
    "                        # 反向传播\n",
    "                        model.zero_grad()\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        for grad, para in zip(message[node], model.parameters()):\n",
    "                            grad.data.add_(1/len(loader), para.grad.data)\n",
    "                    for grad, para in zip(message[node], model.parameters()):\n",
    "                        grad.data.add_(weight_decay, para.data)\n",
    "                \n",
    "                # 保存旧结果\n",
    "                for oldPara, newPara in zip(lastModel.parameters(), model.parameters()):\n",
    "                    oldPara.data.copy_(newPara)\n",
    "                # 同步, Byzantine攻击\n",
    "                message_f = flatten_list(message, byzantineSize)\n",
    "                if attack != None:\n",
    "                    attack(message_f, byzantineSize)\n",
    "                # 聚合\n",
    "                g_vector = aggregate(message_f)\n",
    "                # 展开\n",
    "                g = unflatten_vector(g_vector, model)\n",
    "                # 更新\n",
    "                for para, grad in zip(model.parameters(), g):\n",
    "                    para.data.add_(-gamma, grad)\n",
    "                # 指定下一次停止时间\n",
    "                randomStop = random.randint(1, snapshotInterval-1)\n",
    "                \n",
    "            # 诚实节点更新\n",
    "            for node in range(honestSize):\n",
    "                # 读取数据\n",
    "                material, targets = next(randomIters[node])\n",
    "                \n",
    "                # 随机梯度\n",
    "                # --------------------\n",
    "                # 预测\n",
    "                outputs = model(material)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                # 反向传播\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                # 修正梯度\n",
    "                # --------------------\n",
    "                # 预测\n",
    "                outputs = lastModel(material)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                # 反向传播\n",
    "                lastModel.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # 更新梯度表\n",
    "                for pi, para in enumerate(model.parameters()):\n",
    "                    message[node][pi].data.add_(1, para.grad.data)\n",
    "                    message[node][pi].data.add_(weight_decay, para)\n",
    "                for pi, para in enumerate(lastModel.parameters()):\n",
    "                    message[node][pi].data.sub_(1, para.grad.data)\n",
    "                    message[node][pi].data.sub_(weight_decay, para)\n",
    "\n",
    "            # 同步, Byzantine攻击\n",
    "            message_f = flatten_list(message, byzantineSize)\n",
    "            if attack != None:\n",
    "                attack(message_f, byzantineSize)\n",
    "            # 聚合\n",
    "            g_vector = aggregate(message_f)\n",
    "            # 展开\n",
    "            g = unflatten_vector(g_vector, model)\n",
    "            # 保存旧结果\n",
    "            for oldPara, newPara in zip(lastModel.parameters(), model.parameters()):\n",
    "                oldPara.data.copy_(newPara)\n",
    "            # 更新\n",
    "            for para, grad in zip(model.parameters(), g):\n",
    "                para.data.add_(-gamma, grad)\n",
    "  \n",
    "        var = getVarience(message_f, honestSize)\n",
    "        variencePath.append(var)\n",
    "        \n",
    "        trainLoss, trainAccuracy = calculateAccuracy(model, train_loader)\n",
    "        valLoss, valAccuracy = calculateAccuracy(model, validate_loader)\n",
    "\n",
    "        trainLossPath.append(trainLoss)\n",
    "        trainAccPath.append(trainAccuracy)\n",
    "        valLossPath.append(valLoss)\n",
    "        valAccPath.append(valAccuracy)\n",
    "        \n",
    "        report(r+1, rounds, displayInterval, trainLoss, trainAccuracy, valLoss, valAccuracy)\n",
    "    return model, trainLossPath, trainAccPath, valLossPath, valAccPath, variencePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恶意攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white(messages, byzantinesize):\n",
    "    # 均值相同，方差为1\n",
    "    mu = torch.mean(messages[0:-byzantinesize], dim=0)\n",
    "    messages[-byzantinesize:].copy_(mu)\n",
    "    noise = torch.randn((byzantinesize, messages.size(1)), dtype=torch.float64)\n",
    "#     messages[-byzantinesize:].add_(35, noise)\n",
    "    messages[-byzantinesize:].add_(1, noise)\n",
    "\n",
    "def maxValue(messages, byzantinesize):\n",
    "    # 4倍于正常均值的极大梯度\n",
    "#     mu = torch.mean(messages[0:-byzantinesize], dim=0)\n",
    "#     meliciousMessage = -3*mu\n",
    "#     messages[-byzantinesize:].copy_(meliciousMessage)\n",
    "\n",
    "    mu = torch.mean(w_local[0:-byzantinesize], dim=0)\n",
    "    # 在串行实现中w_local[-1]不会随聚合改变而改变\n",
    "    # w_local[-1]事实上是上一次的迭代值\n",
    "    # w_local[-1] - mu是这次的改变值，即传输过来的向量的改变值\n",
    "    delta = w_local[-1] - mu\n",
    "    meliciousMessage = mu + 4*delta\n",
    "    w_local[-byzantinesize:].copy_(meliciousMessage)\n",
    "\n",
    "def zeroGradient(messages, byzantinesize):\n",
    "    s = torch.sum(messages[0:-byzantinesize], dim=0)\n",
    "    messages[-byzantinesize:].copy_(-s / byzantinesize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, trainloader, device, weight_decay):\n",
    "    \"\"\"\n",
    "    train model using loss_fn and optimizer in an epoch.\n",
    "    model: CNN networks\n",
    "    train_loader: a Dataloader object with training data\n",
    "    loss_func: loss function\n",
    "    device: train on cpu or gpu device\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    trainAccuracy = 0\n",
    "    trainLoss = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (*material, targets) in enumerate(trainloader):\n",
    "        if isinstance(material, torch.Tensor):\n",
    "            material = material.to(device)\n",
    "        else:\n",
    "            material = [m.to(device) for m in material]\n",
    "        \n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(*material)\n",
    "        \n",
    "        loss = loss_func(outputs, targets)\n",
    "        trainLoss += loss.item()\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # AdamW - https://zhuanlan.zhihu.com/p/38945390\n",
    "        for group in optimizer.param_groups:\n",
    "            for param in group['params']:\n",
    "                param.data = param.data.add(-weight_decay * group['lr'], param.data)\n",
    "\n",
    "        # return the maximum value of each row of the input tensor in the \n",
    "        # given dimension dim, the second return vale is the index location\n",
    "        # of each maxium value found(argmax)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        trainAccuracy += (predicted == targets).sum().item()\n",
    "        \n",
    "        total += len(targets)\n",
    "    trainAccuracy /= total\n",
    "    trainLoss /= total\n",
    "    return trainLoss, trainAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loss_func, validateloader, device):\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        # =============================================================\n",
    "        valAccuracy = 0\n",
    "        valLoss = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (*material, targets) in enumerate(trainloader):\n",
    "            if isinstance(material, torch.Tensor):\n",
    "                material = material.to(device)\n",
    "            else:\n",
    "                material = [m.to(device) for m in material]\n",
    "\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(*material)\n",
    "            \n",
    "            loss = loss_func(outputs, targets)\n",
    "            valLoss += loss.item()\n",
    "            \n",
    "            # return the maximum value of each row of the input tensor in the \n",
    "            # given dimension dim, the second return vale is the index location\n",
    "            # of each maxium value found(argmax)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            valAccuracy += (predicted == targets).sum().item()\n",
    "            \n",
    "            total += len(targets)\n",
    "        valAccuracy /= total\n",
    "        valLoss /= total\n",
    "    return valLoss, valAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, classname=None, name='default'):\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        test_cnt = 0\n",
    "        for i, (*material, targets) in enumerate(testloader):\n",
    "            if isinstance(material, torch.Tensor):\n",
    "                material = material.to(device)\n",
    "            else:\n",
    "                material = [m.to(device) for m in material]\n",
    "\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(*material)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "\n",
    "            result.extend(predicted)\n",
    "            test_cnt += len(targets)\n",
    "\n",
    "    if classname != None:\n",
    "        result = [classname[i] for i in result]\n",
    "\n",
    "    log('共预测{}个数据'.format(test_cnt))\n",
    "    df_predict = pd.DataFrame({'id': list(range(1, len(result)+1)), 'polarity': result})\n",
    "    df_predict.to_csv('{}.csv'.format(name), index=False)\n",
    "    log('预测完成')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCurve(list_trainLoss, list_trainAccuracy, list_valLoss, list_valAccuracy):\n",
    "    xAxis = list(range(len(list_trainLoss)))\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    axs[0].plot(xAxis, list_trainLoss, label='train')\n",
    "    axs[0].plot(xAxis, list_valLoss, label='validation')\n",
    "    axs[0].set_title('Loss')\n",
    "\n",
    "    axs[1].plot(xAxis, list_trainAccuracy, label='train')\n",
    "    axs[1].plot(xAxis, list_valAccuracy, label='validation')\n",
    "    axs[1].set_title('Accuracy')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axis()\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('{}'.format(ax.get_title()))\n",
    "        ax.legend()\n",
    "    fig.set_size_inches((8, 4))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(optimizer, aggregate, attack, config, device='cpu'):\n",
    "    # 初始化参数\n",
    "    _config = config.copy()\n",
    "    _config['aggregate'] = aggregate\n",
    "    _config['attack'] = attack\n",
    "    if attack == None:\n",
    "        _config['byzantineSize'] = 0\n",
    "        \n",
    "    model = modelFactory(SEED=_config['SEED'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 记录参数\n",
    "    attackName = 'baseline' if attack == None else attack.__name__\n",
    "    # e.g. Resnet50_SARAH(5)_baseline_mean\n",
    "    title = '{}_{}({})_{}_{}'.format(\n",
    "        model.__class__.__name__, \n",
    "        optimizer.__name__, \n",
    "        _config['batchSize'],\n",
    "        attackName, \n",
    "        aggregate.__name__\n",
    "    )\n",
    "    \n",
    "    # 打印运行信息\n",
    "    print('[提交任务] ' + title)\n",
    "    print('[运行信息]')\n",
    "    print('[网络属性]   name={} parameters number={}'.format(model.__class__.__name__, getPara(model)))\n",
    "    print('[优化方法]   name={} aggregation={} attack={}'.format(optimizer.__name__, aggregate.__name__, attackName))\n",
    "    print('[数据集属性] name={} trainSize={} validationSize={}'.format(dataSetConfig['name'], len(train_dataset), len(validate_dataset)))\n",
    "    print('[优化器设置] gamma={} weight_decay={} batchSize={}'.format(_config['gamma'], _config['weight_decay'], _config['batchSize']))\n",
    "    print('[节点个数]   honestSize={}, byzantineSize={}'.format(_config['honestSize'], _config['byzantineSize']))\n",
    "    print('[运行次数]   rounds={}, displayInterval={}'.format(_config['rounds'], _config['displayInterval']))\n",
    "    print('[torch设置]  device={}, SEED={}, fixSeed={}'.format(device, _config['SEED'], _config['fixSeed']))\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "    # 开始运行\n",
    "    log('优化开始')\n",
    "    res = optimizer(model, device=device, **_config)\n",
    "    [*model, trainLossPath, trainAccPath, valLossPath, valAccPath, variencePath] = res\n",
    "\n",
    "    record = {\n",
    "        **dataSetConfig,\n",
    "        **{key:(_config[key].__name__ if hasattr(_config[key], '__call__') else _config[key]) for key in _config},\n",
    "        'trainLossPath': trainLossPath, \n",
    "        'trainAccPath': trainAccPath, \n",
    "        'valLossPath': valLossPath, \n",
    "        'valAccPath': valAccPath, \n",
    "        'variencePath': variencePath,\n",
    "    }\n",
    "\n",
    "    with open(CACHE_DIR + title, 'wb') as f:\n",
    "        pickle.dump(record, f)\n",
    "    \n",
    "    _, axis = plt.subplots(1, 2)\n",
    "    axis[0].plot(list(range(len(trainLossPath))), trainLossPath, label='train loss')\n",
    "    axis[0].plot(list(range(len(valLossPath))), valLossPath, label='validation loss')\n",
    "    axis[1].plot(list(range(len(trainAccPath))), trainAccPath, label='train accuracy')\n",
    "    axis[1].plot(list(range(len(valAccPath))), valAccPath, label='validation accuracy')\n",
    "    for ax in axis:\n",
    "        ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中心式SGD调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[提交任务] ResNet_CentralSGD(20)_baseline_mean\n",
      "[运行信息]\n",
      "[网络属性]   name=ResNet parameters number=24.37M\n",
      "[优化方法]   name=CentralSGD aggregation=mean attack=baseline\n",
      "[数据集属性] name=CIFAR-10 trainSize=50000 validationSize=10000\n",
      "[优化器设置] gamma=0.5 weight_decay=0.0001 batchSize=20\n",
      "[节点个数]   honestSize=10, byzantineSize=0\n",
      "[运行次数]   rounds=50, displayInterval=6000\n",
      "[torch设置]  device=cuda:0, SEED=100, fixSeed=False\n",
      "-------------------------------------------\n",
      "[10-18 04:44:41] 优化开始\n",
      "[10-18 04:46:48] [0/50](interval: 6000) train: loss=7.2064 acc=0.00 val: loss=7.2071 acc=0.00\n",
      "[10-18 04:57:09] [1/50](interval: 6000) train: loss=1.1190 acc=0.62 val: loss=1.1532 acc=0.61\n",
      "[10-18 05:07:29] [2/50](interval: 6000) train: loss=1.3573 acc=0.69 val: loss=1.5021 acc=0.65\n",
      "[10-18 05:17:50] [3/50](interval: 6000) train: loss=0.7850 acc=0.73 val: loss=0.8774 acc=0.70\n",
      "[10-18 05:28:10] [4/50](interval: 6000) train: loss=0.7875 acc=0.74 val: loss=0.9345 acc=0.70\n",
      "[10-18 05:38:31] [5/50](interval: 6000) train: loss=0.4694 acc=0.84 val: loss=0.6276 acc=0.79\n",
      "[10-18 05:48:51] [6/50](interval: 6000) train: loss=0.6235 acc=0.78 val: loss=0.8023 acc=0.74\n",
      "[10-18 05:59:12] [7/50](interval: 6000) train: loss=0.5739 acc=0.81 val: loss=0.7757 acc=0.76\n",
      "[10-18 06:09:32] [8/50](interval: 6000) train: loss=0.3791 acc=0.87 val: loss=0.5932 acc=0.80\n",
      "[10-18 06:19:52] [9/50](interval: 6000) train: loss=0.4694 acc=0.84 val: loss=0.6657 acc=0.78\n",
      "[10-18 06:30:13] [10/50](interval: 6000) train: loss=0.4121 acc=0.86 val: loss=0.6315 acc=0.79\n",
      "[10-18 06:40:33] [11/50](interval: 6000) train: loss=0.3767 acc=0.87 val: loss=0.6126 acc=0.80\n",
      "[10-18 06:50:53] [12/50](interval: 6000) train: loss=0.6280 acc=0.79 val: loss=0.8862 acc=0.73\n",
      "[10-18 07:01:13] [13/50](interval: 6000) train: loss=0.4165 acc=0.86 val: loss=0.6272 acc=0.79\n",
      "[10-18 07:11:33] [14/50](interval: 6000) train: loss=0.3692 acc=0.87 val: loss=0.6167 acc=0.80\n",
      "[10-18 07:21:53] [15/50](interval: 6000) train: loss=0.3185 acc=0.89 val: loss=0.5490 acc=0.82\n",
      "[10-18 07:32:12] [16/50](interval: 6000) train: loss=0.6290 acc=0.80 val: loss=0.8539 acc=0.74\n",
      "[10-18 07:42:32] [17/50](interval: 6000) train: loss=0.3683 acc=0.88 val: loss=0.6241 acc=0.80\n",
      "[10-18 07:52:52] [18/50](interval: 6000) train: loss=0.4236 acc=0.86 val: loss=0.6661 acc=0.79\n",
      "[10-18 08:03:11] [19/50](interval: 6000) train: loss=0.2603 acc=0.91 val: loss=0.4886 acc=0.84\n",
      "[10-18 08:13:31] [20/50](interval: 6000) train: loss=0.4471 acc=0.85 val: loss=0.7219 acc=0.79\n",
      "[10-18 08:23:50] [21/50](interval: 6000) train: loss=0.3901 acc=0.87 val: loss=0.6221 acc=0.80\n",
      "[10-18 08:34:09] [22/50](interval: 6000) train: loss=0.8510 acc=0.78 val: loss=1.1636 acc=0.72\n",
      "[10-18 08:44:29] [23/50](interval: 6000) train: loss=0.3783 acc=0.88 val: loss=0.6259 acc=0.81\n",
      "[10-18 08:54:48] [24/50](interval: 6000) train: loss=0.4599 acc=0.85 val: loss=0.7205 acc=0.78\n",
      "[10-18 09:05:07] [25/50](interval: 6000) train: loss=0.2882 acc=0.90 val: loss=0.5290 acc=0.82\n",
      "[10-18 09:15:26] [26/50](interval: 6000) train: loss=0.3777 acc=0.87 val: loss=0.6145 acc=0.80\n",
      "[10-18 09:25:46] [27/50](interval: 6000) train: loss=0.2634 acc=0.91 val: loss=0.4971 acc=0.83\n",
      "[10-18 09:36:04] [28/50](interval: 6000) train: loss=0.3766 acc=0.87 val: loss=0.6307 acc=0.80\n",
      "[10-18 09:46:23] [29/50](interval: 6000) train: loss=0.2942 acc=0.90 val: loss=0.5389 acc=0.83\n",
      "[10-18 09:56:41] [30/50](interval: 6000) train: loss=0.3297 acc=0.89 val: loss=0.5940 acc=0.80\n",
      "[10-18 10:06:58] [31/50](interval: 6000) train: loss=0.2469 acc=0.92 val: loss=0.4604 acc=0.85\n",
      "[10-18 10:17:16] [32/50](interval: 6000) train: loss=0.4011 acc=0.87 val: loss=0.6543 acc=0.79\n",
      "[10-18 10:27:34] [33/50](interval: 6000) train: loss=0.3637 acc=0.88 val: loss=0.6136 acc=0.80\n",
      "[10-18 10:37:52] [34/50](interval: 6000) train: loss=0.2716 acc=0.91 val: loss=0.5173 acc=0.84\n",
      "[10-18 10:48:10] [35/50](interval: 6000) train: loss=0.3644 acc=0.88 val: loss=0.6465 acc=0.80\n",
      "[10-18 10:58:28] [36/50](interval: 6000) train: loss=0.4109 acc=0.86 val: loss=0.6728 acc=0.79\n",
      "[10-18 11:08:46] [37/50](interval: 6000) train: loss=0.4305 acc=0.86 val: loss=0.7017 acc=0.78\n",
      "[10-18 11:19:04] [38/50](interval: 6000) train: loss=0.3128 acc=0.89 val: loss=0.5672 acc=0.82\n",
      "[10-18 11:29:22] [39/50](interval: 6000) train: loss=0.3755 acc=0.88 val: loss=0.6564 acc=0.80\n",
      "[10-18 11:39:40] [40/50](interval: 6000) train: loss=0.2595 acc=0.91 val: loss=0.5009 acc=0.84\n",
      "[10-18 11:49:58] [41/50](interval: 6000) train: loss=0.3731 acc=0.88 val: loss=0.6169 acc=0.80\n",
      "[10-18 12:00:16] [42/50](interval: 6000) train: loss=0.2723 acc=0.91 val: loss=0.5232 acc=0.83\n",
      "[10-18 12:10:33] [43/50](interval: 6000) train: loss=0.3042 acc=0.90 val: loss=0.5754 acc=0.82\n",
      "[10-18 12:20:50] [44/50](interval: 6000) train: loss=0.3376 acc=0.88 val: loss=0.6055 acc=0.81\n",
      "[10-18 12:31:08] [45/50](interval: 6000) train: loss=0.4513 acc=0.85 val: loss=0.7583 acc=0.78\n",
      "[10-18 12:41:26] [46/50](interval: 6000) train: loss=0.3658 acc=0.88 val: loss=0.6212 acc=0.81\n",
      "[10-18 12:51:44] [47/50](interval: 6000) train: loss=0.4037 acc=0.86 val: loss=0.6614 acc=0.79\n",
      "[10-18 13:02:02] [48/50](interval: 6000) train: loss=0.3312 acc=0.89 val: loss=0.6075 acc=0.81\n",
      "[10-18 13:12:19] [49/50](interval: 6000) train: loss=0.3425 acc=0.88 val: loss=0.5950 acc=0.81\n",
      "[10-18 13:22:37] [50/50](interval: 6000) train: loss=0.3488 acc=0.88 val: loss=0.6120 acc=0.80\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_config = SGDConfig.copy()\n",
    "_config['gamma'] = 5e-1\n",
    "_config['rounds'] = 50\n",
    "_config['batchSize'] = 20\n",
    "run(optimizer = CentralSGD, aggregate = mean, attack = None, config = _config, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中心式SARAH调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[提交任务] ResNet_CentralSARAH(20)_baseline_mean\n",
      "[运行信息]\n",
      "[网络属性]   name=ResNet parameters number=24.37M\n",
      "[优化方法]   name=CentralSARAH aggregation=mean attack=baseline\n",
      "[数据集属性] name=CIFAR-10 trainSize=50000 validationSize=10000\n",
      "[优化器设置] gamma=0.0001 weight_decay=0.0001 batchSize=20\n",
      "[节点个数]   honestSize=10, byzantineSize=0\n",
      "[运行次数]   rounds=30, displayInterval=100000\n",
      "[torch设置]  device=cuda:0, SEED=100, fixSeed=False\n",
      "-------------------------------------------\n",
      "[11-03 16:27:04] 优化开始\n",
      "[11-03 16:29:34] [SARAH]初始 train: loss=7.043794 accuracy=0.00 validation: loss=7.043365 accuracy=0.00\n",
      "[11-03 22:11:39] [1/30](interval: 100000) train: loss=1.9613 acc=0.28 val: loss=1.9624 acc=0.28\n",
      "[11-04 03:54:06] [2/30](interval: 100000) train: loss=1.8876 acc=0.31 val: loss=1.8835 acc=0.31\n",
      "[11-04 09:29:13] [3/30](interval: 100000) train: loss=1.8333 acc=0.33 val: loss=1.8297 acc=0.33\n",
      "[11-04 15:18:54] [4/30](interval: 100000) train: loss=1.7806 acc=0.35 val: loss=1.7777 acc=0.35\n",
      "[11-04 21:16:08] [5/30](interval: 100000) train: loss=1.7224 acc=0.37 val: loss=1.7231 acc=0.36\n",
      "[11-05 02:39:27] [6/30](interval: 100000) train: loss=1.7634 acc=0.35 val: loss=1.7630 acc=0.34\n",
      "[11-05 08:32:53] [7/30](interval: 100000) train: loss=1.6994 acc=0.37 val: loss=1.7007 acc=0.37\n",
      "[11-05 14:14:50] [8/30](interval: 100000) train: loss=1.6632 acc=0.39 val: loss=1.6666 acc=0.37\n",
      "[11-05 19:45:54] [9/30](interval: 100000) train: loss=1.6655 acc=0.39 val: loss=1.6696 acc=0.38\n",
      "[11-06 01:17:01] [10/30](interval: 100000) train: loss=1.6554 acc=0.39 val: loss=1.6582 acc=0.38\n",
      "[11-06 06:51:52] [11/30](interval: 100000) train: loss=1.6409 acc=0.40 val: loss=1.6442 acc=0.39\n",
      "[11-06 12:20:35] [12/30](interval: 100000) train: loss=1.6222 acc=0.40 val: loss=1.6277 acc=0.39\n",
      "[11-06 17:56:18] [13/30](interval: 100000) train: loss=1.6067 acc=0.41 val: loss=1.6129 acc=0.40\n",
      "[11-06 23:42:30] [14/30](interval: 100000) train: loss=1.5529 acc=0.43 val: loss=1.5624 acc=0.42\n",
      "[11-07 05:29:06] [15/30](interval: 100000) train: loss=1.5867 acc=0.42 val: loss=1.5946 acc=0.41\n",
      "[11-07 11:21:32] [16/30](interval: 100000) train: loss=1.5332 acc=0.44 val: loss=1.5472 acc=0.43\n",
      "[11-07 17:02:15] [17/30](interval: 100000) train: loss=1.5376 acc=0.44 val: loss=1.5555 acc=0.42\n",
      "[11-07 22:51:00] [18/30](interval: 100000) train: loss=1.5244 acc=0.44 val: loss=1.5414 acc=0.43\n",
      "[11-08 04:28:42] [19/30](interval: 100000) train: loss=1.4856 acc=0.45 val: loss=1.5026 acc=0.44\n",
      "[11-08 10:09:02] [20/30](interval: 100000) train: loss=1.4701 acc=0.46 val: loss=1.4902 acc=0.45\n",
      "[11-08 16:10:35] [21/30](interval: 100000) train: loss=1.5125 acc=0.45 val: loss=1.5268 acc=0.44\n",
      "[11-08 22:07:50] [22/30](interval: 100000) train: loss=1.4531 acc=0.47 val: loss=1.4730 acc=0.45\n",
      "[11-09 04:19:44] [23/30](interval: 100000) train: loss=1.4872 acc=0.46 val: loss=1.5002 acc=0.44\n",
      "[11-09 10:05:23] [24/30](interval: 100000) train: loss=1.5744 acc=0.43 val: loss=1.5777 acc=0.42\n",
      "[11-09 15:39:06] [25/30](interval: 100000) train: loss=1.4686 acc=0.47 val: loss=1.4859 acc=0.45\n",
      "[11-09 21:02:45] [26/30](interval: 100000) train: loss=1.5099 acc=0.45 val: loss=1.5249 acc=0.44\n",
      "[11-10 02:40:45] [27/30](interval: 100000) train: loss=1.4652 acc=0.46 val: loss=1.4831 acc=0.46\n",
      "[11-10 08:26:28] [28/30](interval: 100000) train: loss=1.4287 acc=0.48 val: loss=1.4495 acc=0.47\n",
      "[11-10 14:17:50] [29/30](interval: 100000) train: loss=1.4131 acc=0.48 val: loss=1.4355 acc=0.47\n",
      "[11-10 20:29:05] [30/30](interval: 100000) train: loss=1.4051 acc=0.49 val: loss=1.4329 acc=0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_config = SARAHConfig.copy()\n",
    "_config['batchSize'] = 20\n",
    "_config['gamma'] = 1e-4\n",
    "_config['displayInterval'] = 100000\n",
    "_config['rounds'] = 30\n",
    "run(optimizer = CentralSARAH, aggregate = mean, attack = None, config = _config, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[运行信息]\n",
      "[优化方法]   mnist_MLP_SGD(5)_baseline_mean\n",
      "[数据集属性] trainSize=500 validationSize=10000\n",
      "[优化器设置] gamma=0.1 weight_decay=0.0\n",
      "[节点个数]   honestSize=50, byzantineSize=0\n",
      "[运行次数]   rounds=15, displayInterval=1000\n",
      "[torch设置]  device=cpu, SEED=100, fixSeed=False\n",
      "-------------------------------------------\n",
      "[19-09-23 10:30:47] 优化开始\n",
      "[19-09-23 10:30:50] [SGD]初始 train: loss=2.304678 accuracy=0.13 validation: loss=2.304778 accuracy=0.11\n",
      "[19-09-23 10:31:48] [SARAH]已迭代 1/15 rounds (interval: 1000), \n",
      "train: loss=1.643265 accuracy=0.91 validation: loss=1.796671 accuracy=0.74 variance=3.23e-01\n",
      "[19-09-23 10:32:46] [SARAH]已迭代 2/15 rounds (interval: 1000), \n",
      "train: loss=1.529517 accuracy=0.96 validation: loss=1.718004 accuracy=0.79 variance=6.34e-02\n",
      "[19-09-23 10:33:44] [SARAH]已迭代 3/15 rounds (interval: 1000), \n",
      "train: loss=1.509146 accuracy=0.97 validation: loss=1.701012 accuracy=0.80 variance=3.45e-02\n",
      "[19-09-23 10:34:45] [SARAH]已迭代 4/15 rounds (interval: 1000), \n",
      "train: loss=1.497995 accuracy=0.97 validation: loss=1.692937 accuracy=0.80 variance=1.45e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-15425cd6efed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-176-5b9ccf815e6f>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(optimizer, aggregate, attack, config, device)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# 开始运行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'优化开始'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLossPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainAccPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLossPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalAccPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariencePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     record = {\n",
      "\u001b[1;32m<ipython-input-182-d32a6629d343>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(model, gamma, aggregate, weight_decay, honestSize, byzantineSize, attack, rounds, displayInterval, device, SEED, fixSeed, batchSize, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;31m# 反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;31m# 更新梯度表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(optimizer = SGD, aggregate = mean, attack = None, config = SGDConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(optimizer = SGD, aggregate = mean, attack = None, config = SGDConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(optimizer = SGD, aggregate = mean, attack = white, config = SGDConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(optimizer = SGD, aggregate = mean, attack = maxValue, config = SGDConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(optimizer = SGD, aggregate = mean, attack = zeroGradient, config = SGDConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD - geomtric median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "_VRConfig['gamma'] = 2e-2\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_baseline_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "_VRConfig['gamma'] = 2e-2\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_white_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_maxValue_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_zeroGradient_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD - Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=0)\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_baseline_krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "with open(CACHE_DIR + 'SGD_white_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_maxValue_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_zeroGradient_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD - Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_baseline_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_white_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_maxValue_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SGD_zeroGradient_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchSGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchSGD - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_baseline_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_white_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_maxValue_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_zeroGradient_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchSGD - geomtric median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_baseline_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_white_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_maxValue_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = batchConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedBatchSGD(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'batchSize': _VRConfig['batchSize'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'BatchSGD_zeroGradient_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGA - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_baseline_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_white_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_white_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_maxValue_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_linear\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_zeroGradient_mean', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGA - geomtric median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_baseline_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_white_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ff473ac37784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#为CPU设置随机种子\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fmin={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_maxValue_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = aggregate_geometric\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_zeroGradient_gm', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGA - Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=0)\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_baseline_krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "with open(CACHE_DIR + 'SAGA_white_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_maxValue_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = Krum_(nodeSize=dataSetConfig['honestNodeSize'], byzantineSize=dataSetConfig['byzantineNodeSize'])\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path, variancePath = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "    'variancePath': variancePath,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_zeroGradient_Krum', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGA - Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = None\n",
    "_VRConfig['byzantineSize'] = 0\n",
    "w, path = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_baseline_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = whiteNoise\n",
    "w, path = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_white_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = maxValue\n",
    "w, path = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_maxValue_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)#为CPU设置随机种子\n",
    "# torch.cuda.manual_seed(seed)#为当前GPU设置随机种子\n",
    "# torch.cuda.manual_seed_all(seed)#为所有GPU设置随机种子\n",
    "\n",
    "log('Fmin={}'.format(Fmin))\n",
    "\n",
    "_VRConfig = VRConfig.copy()\n",
    "_VRConfig['aggregate'] = median\n",
    "_VRConfig['attack'] = zeroGradient\n",
    "w, path = FedSAGA(w0, **_VRConfig)\n",
    "\n",
    "record = {\n",
    "    **dataSetConfig,\n",
    "    'gamma': _VRConfig['gamma'],\n",
    "    'path': path,\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR + 'SAGA_zeroGradient_median', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "    \n",
    "axis = plt.axes()\n",
    "plt.plot(list(range(len(path))), logAxis(path, Fmin))\n",
    "axis.set_yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "713px",
    "left": "1485px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
